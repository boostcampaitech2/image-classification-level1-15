Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b1-533bc792.pth)
Model(
  (pretrained_model): EfficientNet(
    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): SiLU(inplace=True)
    (blocks): Sequential(
      (0): Sequential(
        (0): DepthwiseSeparableConv(
          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): Identity()
        )
        (1): DepthwiseSeparableConv(
          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): Identity()
        )
      )
      (1): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): InvertedResidual(
          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)
          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): InvertedResidual(
          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
          (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): InvertedResidual(
          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): InvertedResidual(
          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
          (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): InvertedResidual(
          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): InvertedResidual(
          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)
          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)
          (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): InvertedResidual(
          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): InvertedResidual(
          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (4): InvertedResidual(
          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): Sequential(
        (0): InvertedResidual(
          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
          (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): InvertedResidual(
          (conv_pw): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): SiLU(inplace=True)
          (conv_dw): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)
          (bn2): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act2): SiLU(inplace=True)
          (se): SqueezeExcite(
            (conv_reduce): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))
            (act1): SiLU(inplace=True)
            (conv_expand): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))
            (gate): Sigmoid()
          )
          (conv_pwl): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): SiLU(inplace=True)
    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
    (classifier): Linear(in_features=1280, out_features=1000, bias=True)
  )
  (fc): Linear(in_features=1000, out_features=3, bias=True)
)
Trainable parameters: 7797187
cuda:0 1
Train Epoch: 1 [0/21600 (0%)] Loss: 1.232302
Train Epoch: 1 [1408/21600 (7%)] Loss: 0.532354
Train Epoch: 1 [2816/21600 (13%)] Loss: 0.453159
Train Epoch: 1 [4224/21600 (20%)] Loss: 0.396443
Train Epoch: 1 [5632/21600 (26%)] Loss: 0.279620
Train Epoch: 1 [7040/21600 (33%)] Loss: 0.221225
Train Epoch: 1 [8448/21600 (39%)] Loss: 0.409045
Train Epoch: 1 [9856/21600 (46%)] Loss: 0.271057
Train Epoch: 1 [11264/21600 (52%)] Loss: 0.368040
Train Epoch: 1 [12672/21600 (59%)] Loss: 0.207359
Train Epoch: 1 [14080/21600 (65%)] Loss: 0.227995
Train Epoch: 1 [15488/21600 (72%)] Loss: 0.261168
Train Epoch: 1 [16896/21600 (78%)] Loss: 0.214368
Train Epoch: 1 [18304/21600 (85%)] Loss: 0.251594
Train Epoch: 1 [19712/21600 (91%)] Loss: 0.236742
Train Epoch: 1 [21120/21600 (98%)] Loss: 0.248167
    epoch          : 1
    loss           : 0.3304809762175972
    accuracy       : 0.8008660009861932
    f1             : 0.7052133083343506
    val_loss       : 0.23739202424537303
    val_accuracy   : 0.833454457364341
    val_f1         : 0.7009643316268921
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/21600 (0%)] Loss: 0.230498
Train Epoch: 2 [1408/21600 (7%)] Loss: 0.192760
Train Epoch: 2 [2816/21600 (13%)] Loss: 0.271374
Train Epoch: 2 [4224/21600 (20%)] Loss: 0.290696
Train Epoch: 2 [5632/21600 (26%)] Loss: 0.173803
Train Epoch: 2 [7040/21600 (33%)] Loss: 0.208484
Train Epoch: 2 [8448/21600 (39%)] Loss: 0.181094
Train Epoch: 2 [9856/21600 (46%)] Loss: 0.163100
Train Epoch: 2 [11264/21600 (52%)] Loss: 0.175098
Train Epoch: 2 [12672/21600 (59%)] Loss: 0.179292
Train Epoch: 2 [14080/21600 (65%)] Loss: 0.203869
Train Epoch: 2 [15488/21600 (72%)] Loss: 0.223926
Train Epoch: 2 [16896/21600 (78%)] Loss: 0.162406
Train Epoch: 2 [18304/21600 (85%)] Loss: 0.154113
Train Epoch: 2 [19712/21600 (91%)] Loss: 0.190785
Train Epoch: 2 [21120/21600 (98%)] Loss: 0.163625
    epoch          : 2
    loss           : 0.19440027198495244
    accuracy       : 0.8698995315581854
    f1             : 0.7875064611434937
    val_loss       : 0.1902671270938807
    val_accuracy   : 0.8629481589147288
    val_f1         : 0.7740364670753479
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/21600 (0%)] Loss: 0.215688
Train Epoch: 3 [1408/21600 (7%)] Loss: 0.156008
Train Epoch: 3 [2816/21600 (13%)] Loss: 0.132073
Train Epoch: 3 [4224/21600 (20%)] Loss: 0.140665
Train Epoch: 3 [5632/21600 (26%)] Loss: 0.235820
Train Epoch: 3 [7040/21600 (33%)] Loss: 0.138459
Train Epoch: 3 [8448/21600 (39%)] Loss: 0.112167
Train Epoch: 3 [9856/21600 (46%)] Loss: 0.175426
Train Epoch: 3 [11264/21600 (52%)] Loss: 0.138152
Train Epoch: 3 [12672/21600 (59%)] Loss: 0.126395
Train Epoch: 3 [14080/21600 (65%)] Loss: 0.165127
Train Epoch: 3 [15488/21600 (72%)] Loss: 0.133549
Train Epoch: 3 [16896/21600 (78%)] Loss: 0.119901
Train Epoch: 3 [18304/21600 (85%)] Loss: 0.099967
Train Epoch: 3 [19712/21600 (91%)] Loss: 0.116557
Train Epoch: 3 [21120/21600 (98%)] Loss: 0.139477
    epoch          : 3
    loss           : 0.15172038831301696
    accuracy       : 0.8956792406311637
    f1             : 0.8328374624252319
    val_loss       : 0.1556641857984454
    val_accuracy   : 0.8859011627906976
    val_f1         : 0.8156247735023499
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/21600 (0%)] Loss: 0.108399
Train Epoch: 4 [1408/21600 (7%)] Loss: 0.133098
Train Epoch: 4 [2816/21600 (13%)] Loss: 0.118153
Train Epoch: 4 [4224/21600 (20%)] Loss: 0.095134
Train Epoch: 4 [5632/21600 (26%)] Loss: 0.096469
Train Epoch: 4 [7040/21600 (33%)] Loss: 0.097780
Train Epoch: 4 [8448/21600 (39%)] Loss: 0.104358
Train Epoch: 4 [9856/21600 (46%)] Loss: 0.098685
Train Epoch: 4 [11264/21600 (52%)] Loss: 0.102283
Train Epoch: 4 [12672/21600 (59%)] Loss: 0.088482
Train Epoch: 4 [14080/21600 (65%)] Loss: 0.155801
Train Epoch: 4 [15488/21600 (72%)] Loss: 0.119507
Train Epoch: 4 [16896/21600 (78%)] Loss: 0.141164
Train Epoch: 4 [18304/21600 (85%)] Loss: 0.101148
Train Epoch: 4 [19712/21600 (91%)] Loss: 0.165648
Train Epoch: 4 [21120/21600 (98%)] Loss: 0.128292
    epoch          : 4
    loss           : 0.11941570336737577
    accuracy       : 0.9174525394477318
    f1             : 0.8693379163742065
    val_loss       : 0.13477466688599699
    val_accuracy   : 0.9114583333333334
    val_f1         : 0.8615548610687256
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch4.pth ...
Saving current best: model_best.pth ...
Train Epoch: 5 [0/21600 (0%)] Loss: 0.089635
Train Epoch: 5 [1408/21600 (7%)] Loss: 0.152945
Train Epoch: 5 [2816/21600 (13%)] Loss: 0.099799
Train Epoch: 5 [4224/21600 (20%)] Loss: 0.123114
Train Epoch: 5 [5632/21600 (26%)] Loss: 0.069839
Train Epoch: 5 [7040/21600 (33%)] Loss: 0.095453
Train Epoch: 5 [8448/21600 (39%)] Loss: 0.123303
Train Epoch: 5 [9856/21600 (46%)] Loss: 0.071568
Train Epoch: 5 [11264/21600 (52%)] Loss: 0.087643
Train Epoch: 5 [12672/21600 (59%)] Loss: 0.104134
Train Epoch: 5 [14080/21600 (65%)] Loss: 0.088689
Train Epoch: 5 [15488/21600 (72%)] Loss: 0.100422
Train Epoch: 5 [16896/21600 (78%)] Loss: 0.079133
Train Epoch: 5 [18304/21600 (85%)] Loss: 0.068860
Train Epoch: 5 [19712/21600 (91%)] Loss: 0.061054
Train Epoch: 5 [21120/21600 (98%)] Loss: 0.087628
    epoch          : 5
    loss           : 0.09806502694208946
    accuracy       : 0.9379930966469429
    f1             : 0.9055525064468384
    val_loss       : 0.1283968354380408
    val_accuracy   : 0.9183018410852712
    val_f1         : 0.8766067624092102
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch5.pth ...
Saving current best: model_best.pth ...
Train Epoch: 6 [0/21600 (0%)] Loss: 0.097284
Train Epoch: 6 [1408/21600 (7%)] Loss: 0.081022
Train Epoch: 6 [2816/21600 (13%)] Loss: 0.064359
Train Epoch: 6 [4224/21600 (20%)] Loss: 0.114541
Train Epoch: 6 [5632/21600 (26%)] Loss: 0.078299
Train Epoch: 6 [7040/21600 (33%)] Loss: 0.100122
Train Epoch: 6 [8448/21600 (39%)] Loss: 0.066143
Train Epoch: 6 [9856/21600 (46%)] Loss: 0.158534
Train Epoch: 6 [11264/21600 (52%)] Loss: 0.037505
Train Epoch: 6 [12672/21600 (59%)] Loss: 0.056387
Train Epoch: 6 [14080/21600 (65%)] Loss: 0.088597
Train Epoch: 6 [15488/21600 (72%)] Loss: 0.102517
Train Epoch: 6 [16896/21600 (78%)] Loss: 0.038074
Train Epoch: 6 [18304/21600 (85%)] Loss: 0.078119
Train Epoch: 6 [19712/21600 (91%)] Loss: 0.033937
Train Epoch: 6 [21120/21600 (98%)] Loss: 0.075792
    epoch          : 6
    loss           : 0.07738954055855965
    accuracy       : 0.951090976331361
    f1             : 0.9271599650382996
    val_loss       : 0.11590256169438362
    val_accuracy   : 0.9269016472868218
    val_f1         : 0.8872303366661072
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch6.pth ...
Saving current best: model_best.pth ...
Train Epoch: 7 [0/21600 (0%)] Loss: 0.111285
Train Epoch: 7 [1408/21600 (7%)] Loss: 0.070624
Train Epoch: 7 [2816/21600 (13%)] Loss: 0.056184
Train Epoch: 7 [4224/21600 (20%)] Loss: 0.074273
Train Epoch: 7 [5632/21600 (26%)] Loss: 0.050237
Train Epoch: 7 [7040/21600 (33%)] Loss: 0.047420
Train Epoch: 7 [8448/21600 (39%)] Loss: 0.053604
Train Epoch: 7 [9856/21600 (46%)] Loss: 0.036173
Train Epoch: 7 [11264/21600 (52%)] Loss: 0.058845
Train Epoch: 7 [12672/21600 (59%)] Loss: 0.031454
Train Epoch: 7 [14080/21600 (65%)] Loss: 0.050093
Train Epoch: 7 [15488/21600 (72%)] Loss: 0.061057
Train Epoch: 7 [16896/21600 (78%)] Loss: 0.020623
Train Epoch: 7 [18304/21600 (85%)] Loss: 0.092743
Train Epoch: 7 [19712/21600 (91%)] Loss: 0.046833
Train Epoch: 7 [21120/21600 (98%)] Loss: 0.041051
    epoch          : 7
    loss           : 0.06620739503989559
    accuracy       : 0.9597355769230769
    f1             : 0.9423049092292786
    val_loss       : 0.10194062692827957
    val_accuracy   : 0.9343507751937985
    val_f1         : 0.9006338119506836
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch7.pth ...
Saving current best: model_best.pth ...
Train Epoch: 8 [0/21600 (0%)] Loss: 0.054094
Train Epoch: 8 [1408/21600 (7%)] Loss: 0.050686
Train Epoch: 8 [2816/21600 (13%)] Loss: 0.028749
Train Epoch: 8 [4224/21600 (20%)] Loss: 0.046357
Train Epoch: 8 [5632/21600 (26%)] Loss: 0.069790
Train Epoch: 8 [7040/21600 (33%)] Loss: 0.043671
Train Epoch: 8 [8448/21600 (39%)] Loss: 0.071279
Train Epoch: 8 [9856/21600 (46%)] Loss: 0.085599
Train Epoch: 8 [11264/21600 (52%)] Loss: 0.074729
Train Epoch: 8 [12672/21600 (59%)] Loss: 0.028473
Train Epoch: 8 [14080/21600 (65%)] Loss: 0.073771
Train Epoch: 8 [15488/21600 (72%)] Loss: 0.072979
Train Epoch: 8 [16896/21600 (78%)] Loss: 0.060370
Train Epoch: 8 [18304/21600 (85%)] Loss: 0.066851
Train Epoch: 8 [19712/21600 (91%)] Loss: 0.030117
Train Epoch: 8 [21120/21600 (98%)] Loss: 0.080159
    epoch          : 8
    loss           : 0.057061820494881746
    accuracy       : 0.9669779339250494
    f1             : 0.9533393383026123
    val_loss       : 0.09532696348723284
    val_accuracy   : 0.9484011627906976
    val_f1         : 0.9288938641548157
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch8.pth ...
Saving current best: model_best.pth ...
Train Epoch: 9 [0/21600 (0%)] Loss: 0.024496
Train Epoch: 9 [1408/21600 (7%)] Loss: 0.078225
Train Epoch: 9 [2816/21600 (13%)] Loss: 0.041165
Train Epoch: 9 [4224/21600 (20%)] Loss: 0.054919
Train Epoch: 9 [5632/21600 (26%)] Loss: 0.093599
Train Epoch: 9 [7040/21600 (33%)] Loss: 0.052615
Train Epoch: 9 [8448/21600 (39%)] Loss: 0.049059
Train Epoch: 9 [9856/21600 (46%)] Loss: 0.011950
Train Epoch: 9 [11264/21600 (52%)] Loss: 0.022059
Train Epoch: 9 [12672/21600 (59%)] Loss: 0.058781
Train Epoch: 9 [14080/21600 (65%)] Loss: 0.038303
Train Epoch: 9 [15488/21600 (72%)] Loss: 0.103179
Train Epoch: 9 [16896/21600 (78%)] Loss: 0.020449
Train Epoch: 9 [18304/21600 (85%)] Loss: 0.032151
Train Epoch: 9 [19712/21600 (91%)] Loss: 0.058249
Train Epoch: 9 [21120/21600 (98%)] Loss: 0.043348
    epoch          : 9
    loss           : 0.04909509098565085
    accuracy       : 0.9738812869822485
    f1             : 0.9639195799827576
    val_loss       : 0.08288672488442687
    val_accuracy   : 0.9487039728682171
    val_f1         : 0.9260572195053101
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch9.pth ...
Saving current best: model_best.pth ...
Train Epoch: 10 [0/21600 (0%)] Loss: 0.041527
Train Epoch: 10 [1408/21600 (7%)] Loss: 0.025864
Train Epoch: 10 [2816/21600 (13%)] Loss: 0.028754
Train Epoch: 10 [4224/21600 (20%)] Loss: 0.015336
Train Epoch: 10 [5632/21600 (26%)] Loss: 0.039277
Train Epoch: 10 [7040/21600 (33%)] Loss: 0.016427
Train Epoch: 10 [8448/21600 (39%)] Loss: 0.036065
Train Epoch: 10 [9856/21600 (46%)] Loss: 0.127492
Train Epoch: 10 [11264/21600 (52%)] Loss: 0.030167
Train Epoch: 10 [12672/21600 (59%)] Loss: 0.031841
Train Epoch: 10 [14080/21600 (65%)] Loss: 0.070523
Train Epoch: 10 [15488/21600 (72%)] Loss: 0.045538
Train Epoch: 10 [16896/21600 (78%)] Loss: 0.044988
Train Epoch: 10 [18304/21600 (85%)] Loss: 0.073270
Train Epoch: 10 [19712/21600 (91%)] Loss: 0.082641
Train Epoch: 10 [21120/21600 (98%)] Loss: 0.032370
    epoch          : 10
    loss           : 0.04228562148585475
    accuracy       : 0.9771480522682446
    f1             : 0.968751072883606
    val_loss       : 0.08054755885847086
    val_accuracy   : 0.9509447674418605
    val_f1         : 0.928351104259491
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch10.pth ...
Saving current best: model_best.pth ...
Train Epoch: 11 [0/21600 (0%)] Loss: 0.032246
Train Epoch: 11 [1408/21600 (7%)] Loss: 0.049019
Train Epoch: 11 [2816/21600 (13%)] Loss: 0.045615
Train Epoch: 11 [4224/21600 (20%)] Loss: 0.020493
Train Epoch: 11 [5632/21600 (26%)] Loss: 0.045391
Train Epoch: 11 [7040/21600 (33%)] Loss: 0.052039
Train Epoch: 11 [8448/21600 (39%)] Loss: 0.021448
Train Epoch: 11 [9856/21600 (46%)] Loss: 0.014901
Train Epoch: 11 [11264/21600 (52%)] Loss: 0.044162
Train Epoch: 11 [12672/21600 (59%)] Loss: 0.053376
Train Epoch: 11 [14080/21600 (65%)] Loss: 0.040567
Train Epoch: 11 [15488/21600 (72%)] Loss: 0.023583
Train Epoch: 11 [16896/21600 (78%)] Loss: 0.069831
Train Epoch: 11 [18304/21600 (85%)] Loss: 0.015509
Train Epoch: 11 [19712/21600 (91%)] Loss: 0.026804
Train Epoch: 11 [21120/21600 (98%)] Loss: 0.028572
    epoch          : 11
    loss           : 0.041082561065679826
    accuracy       : 0.9768552761341223
    f1             : 0.9681630730628967
    val_loss       : 0.07775667537177025
    val_accuracy   : 0.9517320736434108
    val_f1         : 0.9314215779304504
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch11.pth ...
Saving current best: model_best.pth ...
Train Epoch: 12 [0/21600 (0%)] Loss: 0.022815
Train Epoch: 12 [1408/21600 (7%)] Loss: 0.108781
Train Epoch: 12 [2816/21600 (13%)] Loss: 0.025306
Train Epoch: 12 [4224/21600 (20%)] Loss: 0.038913
Train Epoch: 12 [5632/21600 (26%)] Loss: 0.069106
Train Epoch: 12 [7040/21600 (33%)] Loss: 0.113326
Train Epoch: 12 [8448/21600 (39%)] Loss: 0.078585
Train Epoch: 12 [9856/21600 (46%)] Loss: 0.020134
Train Epoch: 12 [11264/21600 (52%)] Loss: 0.014327
Train Epoch: 12 [12672/21600 (59%)] Loss: 0.031424
Train Epoch: 12 [14080/21600 (65%)] Loss: 0.029851
Train Epoch: 12 [15488/21600 (72%)] Loss: 0.024204
Train Epoch: 12 [16896/21600 (78%)] Loss: 0.048790
Train Epoch: 12 [18304/21600 (85%)] Loss: 0.023870
Train Epoch: 12 [19712/21600 (91%)] Loss: 0.058784
Train Epoch: 12 [21120/21600 (98%)] Loss: 0.033865
    epoch          : 12
    loss           : 0.03869597421485115
    accuracy       : 0.9789663461538461
    f1             : 0.9715749621391296
    val_loss       : 0.07554723650520277
    val_accuracy   : 0.9585755813953488
    val_f1         : 0.9419018030166626
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch12.pth ...
Saving current best: model_best.pth ...
Train Epoch: 13 [0/21600 (0%)] Loss: 0.030481
Train Epoch: 13 [1408/21600 (7%)] Loss: 0.021661
Train Epoch: 13 [2816/21600 (13%)] Loss: 0.013088
Train Epoch: 13 [4224/21600 (20%)] Loss: 0.013840
Train Epoch: 13 [5632/21600 (26%)] Loss: 0.035570
Train Epoch: 13 [7040/21600 (33%)] Loss: 0.051158
Train Epoch: 13 [8448/21600 (39%)] Loss: 0.018019
Train Epoch: 13 [9856/21600 (46%)] Loss: 0.029448
Train Epoch: 13 [11264/21600 (52%)] Loss: 0.022023
Train Epoch: 13 [12672/21600 (59%)] Loss: 0.011426
Train Epoch: 13 [14080/21600 (65%)] Loss: 0.015565
Train Epoch: 13 [15488/21600 (72%)] Loss: 0.019297
Train Epoch: 13 [16896/21600 (78%)] Loss: 0.013355
Train Epoch: 13 [18304/21600 (85%)] Loss: 0.033228
Train Epoch: 13 [19712/21600 (91%)] Loss: 0.046210
Train Epoch: 13 [21120/21600 (98%)] Loss: 0.035652
    epoch          : 13
    loss           : 0.034726531547907544
    accuracy       : 0.9816629684418146
    f1             : 0.9745481610298157
    val_loss       : 0.07363648400750271
    val_accuracy   : 0.9588783914728682
    val_f1         : 0.9398607015609741
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch13.pth ...
Saving current best: model_best.pth ...
Train Epoch: 14 [0/21600 (0%)] Loss: 0.065084
Train Epoch: 14 [1408/21600 (7%)] Loss: 0.024842
Train Epoch: 14 [2816/21600 (13%)] Loss: 0.020892
Train Epoch: 14 [4224/21600 (20%)] Loss: 0.036929
Train Epoch: 14 [5632/21600 (26%)] Loss: 0.057961
Train Epoch: 14 [7040/21600 (33%)] Loss: 0.066833
Train Epoch: 14 [8448/21600 (39%)] Loss: 0.022004
Train Epoch: 14 [9856/21600 (46%)] Loss: 0.018214
Train Epoch: 14 [11264/21600 (52%)] Loss: 0.031866
Train Epoch: 14 [12672/21600 (59%)] Loss: 0.036288
Train Epoch: 14 [14080/21600 (65%)] Loss: 0.027858
Train Epoch: 14 [15488/21600 (72%)] Loss: 0.042629
Train Epoch: 14 [16896/21600 (78%)] Loss: 0.040193
Train Epoch: 14 [18304/21600 (85%)] Loss: 0.017805
Train Epoch: 14 [19712/21600 (91%)] Loss: 0.066876
Train Epoch: 14 [21120/21600 (98%)] Loss: 0.063869
    epoch          : 14
    loss           : 0.032765426287240176
    accuracy       : 0.9813239644970414
    f1             : 0.9748022556304932
    val_loss       : 0.06535225621489592
    val_accuracy   : 0.9662063953488372
    val_f1         : 0.9525014162063599
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch14.pth ...
Saving current best: model_best.pth ...
Train Epoch: 15 [0/21600 (0%)] Loss: 0.016158
Train Epoch: 15 [1408/21600 (7%)] Loss: 0.052284
Train Epoch: 15 [2816/21600 (13%)] Loss: 0.037071
Train Epoch: 15 [4224/21600 (20%)] Loss: 0.037261
Train Epoch: 15 [5632/21600 (26%)] Loss: 0.028762
Train Epoch: 15 [7040/21600 (33%)] Loss: 0.025395
Train Epoch: 15 [8448/21600 (39%)] Loss: 0.011017
Train Epoch: 15 [9856/21600 (46%)] Loss: 0.027980
Train Epoch: 15 [11264/21600 (52%)] Loss: 0.062062
Train Epoch: 15 [12672/21600 (59%)] Loss: 0.025605
Train Epoch: 15 [14080/21600 (65%)] Loss: 0.047572
Train Epoch: 15 [15488/21600 (72%)] Loss: 0.028286
Train Epoch: 15 [16896/21600 (78%)] Loss: 0.013174
Train Epoch: 15 [18304/21600 (85%)] Loss: 0.029062
Train Epoch: 15 [19712/21600 (91%)] Loss: 0.009699
Train Epoch: 15 [21120/21600 (98%)] Loss: 0.043597
    epoch          : 15
    loss           : 0.03152030021415131
    accuracy       : 0.9834350345167654
    f1             : 0.9781500697135925
    val_loss       : 0.06956213210211244
    val_accuracy   : 0.9637839147286822
    val_f1         : 0.9498022794723511
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch15.pth ...
Train Epoch: 16 [0/21600 (0%)] Loss: 0.027219
Train Epoch: 16 [1408/21600 (7%)] Loss: 0.020106
Train Epoch: 16 [2816/21600 (13%)] Loss: 0.019937
Train Epoch: 16 [4224/21600 (20%)] Loss: 0.017462
Train Epoch: 16 [5632/21600 (26%)] Loss: 0.068221
Train Epoch: 16 [7040/21600 (33%)] Loss: 0.035928
Train Epoch: 16 [8448/21600 (39%)] Loss: 0.037722
Train Epoch: 16 [9856/21600 (46%)] Loss: 0.027750
Train Epoch: 16 [11264/21600 (52%)] Loss: 0.024827
Train Epoch: 16 [12672/21600 (59%)] Loss: 0.034731
Train Epoch: 16 [14080/21600 (65%)] Loss: 0.050671
Train Epoch: 16 [15488/21600 (72%)] Loss: 0.029537
Train Epoch: 16 [16896/21600 (78%)] Loss: 0.014696
Train Epoch: 16 [18304/21600 (85%)] Loss: 0.051977
Train Epoch: 16 [19712/21600 (91%)] Loss: 0.027404
Train Epoch: 16 [21120/21600 (98%)] Loss: 0.007726
    epoch          : 16
    loss           : 0.03238622176312131
    accuracy       : 0.9831114398422092
    f1             : 0.977055013179779
    val_loss       : 0.06420718337041001
    val_accuracy   : 0.969234496124031
    val_f1         : 0.9586480855941772
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch16.pth ...
Saving current best: model_best.pth ...
Train Epoch: 17 [0/21600 (0%)] Loss: 0.008436
Train Epoch: 17 [1408/21600 (7%)] Loss: 0.010347
Train Epoch: 17 [2816/21600 (13%)] Loss: 0.043155
Train Epoch: 17 [4224/21600 (20%)] Loss: 0.026448
Train Epoch: 17 [5632/21600 (26%)] Loss: 0.026049
Train Epoch: 17 [7040/21600 (33%)] Loss: 0.023196
Train Epoch: 17 [8448/21600 (39%)] Loss: 0.057492
Train Epoch: 17 [9856/21600 (46%)] Loss: 0.027118
Train Epoch: 17 [11264/21600 (52%)] Loss: 0.052392
Train Epoch: 17 [12672/21600 (59%)] Loss: 0.012205
Train Epoch: 17 [14080/21600 (65%)] Loss: 0.026945
Train Epoch: 17 [15488/21600 (72%)] Loss: 0.052078
Train Epoch: 17 [16896/21600 (78%)] Loss: 0.055151
Train Epoch: 17 [18304/21600 (85%)] Loss: 0.008833
Train Epoch: 17 [19712/21600 (91%)] Loss: 0.020023
Train Epoch: 17 [21120/21600 (98%)] Loss: 0.040116
    epoch          : 17
    loss           : 0.02848358522582601
    accuracy       : 0.9836661735700197
    f1             : 0.9775753617286682
    val_loss       : 0.05638230611505204
    val_accuracy   : 0.9723837209302325
    val_f1         : 0.9628564715385437
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch17.pth ...
Saving current best: model_best.pth ...
Train Epoch: 18 [0/21600 (0%)] Loss: 0.011757
Train Epoch: 18 [1408/21600 (7%)] Loss: 0.039831
Train Epoch: 18 [2816/21600 (13%)] Loss: 0.006446
Train Epoch: 18 [4224/21600 (20%)] Loss: 0.007723
Train Epoch: 18 [5632/21600 (26%)] Loss: 0.015638
Train Epoch: 18 [7040/21600 (33%)] Loss: 0.033934
Train Epoch: 18 [8448/21600 (39%)] Loss: 0.025722
Train Epoch: 18 [9856/21600 (46%)] Loss: 0.007312
Train Epoch: 18 [11264/21600 (52%)] Loss: 0.051761
Train Epoch: 18 [12672/21600 (59%)] Loss: 0.013239
Train Epoch: 18 [14080/21600 (65%)] Loss: 0.007871
Train Epoch: 18 [15488/21600 (72%)] Loss: 0.023290
Train Epoch: 18 [16896/21600 (78%)] Loss: 0.025851
Train Epoch: 18 [18304/21600 (85%)] Loss: 0.018570
Train Epoch: 18 [19712/21600 (91%)] Loss: 0.014266
Train Epoch: 18 [21120/21600 (98%)] Loss: 0.015393
    epoch          : 18
    loss           : 0.026954745734661553
    accuracy       : 0.9855152859960553
    f1             : 0.980262279510498
    val_loss       : 0.05851857721545668
    val_accuracy   : 0.9685077519379846
    val_f1         : 0.9563704133033752
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch18.pth ...
Train Epoch: 19 [0/21600 (0%)] Loss: 0.012907
Train Epoch: 19 [1408/21600 (7%)] Loss: 0.006246
Train Epoch: 19 [2816/21600 (13%)] Loss: 0.020265
Train Epoch: 19 [4224/21600 (20%)] Loss: 0.023244
Train Epoch: 19 [5632/21600 (26%)] Loss: 0.027217
Train Epoch: 19 [7040/21600 (33%)] Loss: 0.019857
Train Epoch: 19 [8448/21600 (39%)] Loss: 0.021266
Train Epoch: 19 [9856/21600 (46%)] Loss: 0.035260
Train Epoch: 19 [11264/21600 (52%)] Loss: 0.022278
Train Epoch: 19 [12672/21600 (59%)] Loss: 0.057699
Train Epoch: 19 [14080/21600 (65%)] Loss: 0.028639
Train Epoch: 19 [15488/21600 (72%)] Loss: 0.035005
Train Epoch: 19 [16896/21600 (78%)] Loss: 0.017748
Train Epoch: 19 [18304/21600 (85%)] Loss: 0.018759
Train Epoch: 19 [19712/21600 (91%)] Loss: 0.009546
Train Epoch: 19 [21120/21600 (98%)] Loss: 0.021086
    epoch          : 19
    loss           : 0.025431521424263186
    accuracy       : 0.9855769230769231
    f1             : 0.9808177947998047
    val_loss       : 0.05365242291415154
    val_accuracy   : 0.9720203488372093
    val_f1         : 0.9620041847229004
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch19.pth ...
Saving current best: model_best.pth ...
Train Epoch: 20 [0/21600 (0%)] Loss: 0.041611
Train Epoch: 20 [1408/21600 (7%)] Loss: 0.026784
Train Epoch: 20 [2816/21600 (13%)] Loss: 0.020088
Train Epoch: 20 [4224/21600 (20%)] Loss: 0.071424
Train Epoch: 20 [5632/21600 (26%)] Loss: 0.011163
Train Epoch: 20 [7040/21600 (33%)] Loss: 0.009433
Train Epoch: 20 [8448/21600 (39%)] Loss: 0.029106
Train Epoch: 20 [9856/21600 (46%)] Loss: 0.019961
Train Epoch: 20 [11264/21600 (52%)] Loss: 0.017544
Train Epoch: 20 [12672/21600 (59%)] Loss: 0.005602
Train Epoch: 20 [14080/21600 (65%)] Loss: 0.018223
Train Epoch: 20 [15488/21600 (72%)] Loss: 0.033830
Train Epoch: 20 [16896/21600 (78%)] Loss: 0.024935
Train Epoch: 20 [18304/21600 (85%)] Loss: 0.019924
Train Epoch: 20 [19712/21600 (91%)] Loss: 0.020267
Train Epoch: 20 [21120/21600 (98%)] Loss: 0.051946
    epoch          : 20
    loss           : 0.0252427050661979
    accuracy       : 0.9856385601577908
    f1             : 0.9807105660438538
    val_loss       : 0.05357232543661497
    val_accuracy   : 0.9694767441860465
    val_f1         : 0.9582716226577759
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch20.pth ...
Saving current best: model_best.pth ...
Train Epoch: 21 [0/21600 (0%)] Loss: 0.018200
Train Epoch: 21 [1408/21600 (7%)] Loss: 0.026063
Train Epoch: 21 [2816/21600 (13%)] Loss: 0.022400
Train Epoch: 21 [4224/21600 (20%)] Loss: 0.016013
Train Epoch: 21 [5632/21600 (26%)] Loss: 0.007203
Train Epoch: 21 [7040/21600 (33%)] Loss: 0.012738
Train Epoch: 21 [8448/21600 (39%)] Loss: 0.025296
Train Epoch: 21 [9856/21600 (46%)] Loss: 0.016775
Train Epoch: 21 [11264/21600 (52%)] Loss: 0.008781
Train Epoch: 21 [12672/21600 (59%)] Loss: 0.040038
Train Epoch: 21 [14080/21600 (65%)] Loss: 0.032203
Train Epoch: 21 [15488/21600 (72%)] Loss: 0.014950
Train Epoch: 21 [16896/21600 (78%)] Loss: 0.037872
Train Epoch: 21 [18304/21600 (85%)] Loss: 0.020292
Train Epoch: 21 [19712/21600 (91%)] Loss: 0.017832
Train Epoch: 21 [21120/21600 (98%)] Loss: 0.027184
    epoch          : 21
    loss           : 0.023868151423769326
    accuracy       : 0.9863782051282051
    f1             : 0.9814653396606445
    val_loss       : 0.05396269948416671
    val_accuracy   : 0.970687984496124
    val_f1         : 0.9606396555900574
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch21.pth ...
Train Epoch: 22 [0/21600 (0%)] Loss: 0.018895
Train Epoch: 22 [1408/21600 (7%)] Loss: 0.026749
Train Epoch: 22 [2816/21600 (13%)] Loss: 0.027954
Train Epoch: 22 [4224/21600 (20%)] Loss: 0.006916
Train Epoch: 22 [5632/21600 (26%)] Loss: 0.004967
Train Epoch: 22 [7040/21600 (33%)] Loss: 0.094062
Train Epoch: 22 [8448/21600 (39%)] Loss: 0.005564
Train Epoch: 22 [9856/21600 (46%)] Loss: 0.010920
Train Epoch: 22 [11264/21600 (52%)] Loss: 0.023265
Train Epoch: 22 [12672/21600 (59%)] Loss: 0.025128
Train Epoch: 22 [14080/21600 (65%)] Loss: 0.025425
Train Epoch: 22 [15488/21600 (72%)] Loss: 0.011138
Train Epoch: 22 [16896/21600 (78%)] Loss: 0.023661
Train Epoch: 22 [18304/21600 (85%)] Loss: 0.010108
Train Epoch: 22 [19712/21600 (91%)] Loss: 0.016747
Train Epoch: 22 [21120/21600 (98%)] Loss: 0.039863
    epoch          : 22
    loss           : 0.02476986205569033
    accuracy       : 0.9861778846153846
    f1             : 0.9820698499679565
    val_loss       : 0.052161984578814616
    val_accuracy   : 0.9747456395348837
    val_f1         : 0.9656823873519897
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch22.pth ...
Saving current best: model_best.pth ...
Train Epoch: 23 [0/21600 (0%)] Loss: 0.004050
Train Epoch: 23 [1408/21600 (7%)] Loss: 0.037954
Train Epoch: 23 [2816/21600 (13%)] Loss: 0.008552
Train Epoch: 23 [4224/21600 (20%)] Loss: 0.020380
Train Epoch: 23 [5632/21600 (26%)] Loss: 0.028936
Train Epoch: 23 [7040/21600 (33%)] Loss: 0.011558
Train Epoch: 23 [8448/21600 (39%)] Loss: 0.058756
Train Epoch: 23 [9856/21600 (46%)] Loss: 0.038997
Train Epoch: 23 [11264/21600 (52%)] Loss: 0.040260
Train Epoch: 23 [12672/21600 (59%)] Loss: 0.002697
Train Epoch: 23 [14080/21600 (65%)] Loss: 0.014220
Train Epoch: 23 [15488/21600 (72%)] Loss: 0.012346
Train Epoch: 23 [16896/21600 (78%)] Loss: 0.018397
Train Epoch: 23 [18304/21600 (85%)] Loss: 0.040661
Train Epoch: 23 [19712/21600 (91%)] Loss: 0.014281
Train Epoch: 23 [21120/21600 (98%)] Loss: 0.042454
    epoch          : 23
    loss           : 0.024864264320273548
    accuracy       : 0.9864860700197239
    f1             : 0.9815601706504822
    val_loss       : 0.04900610180528358
    val_accuracy   : 0.9745639534883721
    val_f1         : 0.9646406173706055
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch23.pth ...
Saving current best: model_best.pth ...
Train Epoch: 24 [0/21600 (0%)] Loss: 0.025884
Train Epoch: 24 [1408/21600 (7%)] Loss: 0.009596
Train Epoch: 24 [2816/21600 (13%)] Loss: 0.024347
Train Epoch: 24 [4224/21600 (20%)] Loss: 0.025794
Train Epoch: 24 [5632/21600 (26%)] Loss: 0.017785
Train Epoch: 24 [7040/21600 (33%)] Loss: 0.041436
Train Epoch: 24 [8448/21600 (39%)] Loss: 0.016212
Train Epoch: 24 [9856/21600 (46%)] Loss: 0.010323
Train Epoch: 24 [11264/21600 (52%)] Loss: 0.012014
Train Epoch: 24 [12672/21600 (59%)] Loss: 0.004517
Train Epoch: 24 [14080/21600 (65%)] Loss: 0.013662
Train Epoch: 24 [15488/21600 (72%)] Loss: 0.042854
Train Epoch: 24 [16896/21600 (78%)] Loss: 0.002883
Train Epoch: 24 [18304/21600 (85%)] Loss: 0.004609
Train Epoch: 24 [19712/21600 (91%)] Loss: 0.029484
Train Epoch: 24 [21120/21600 (98%)] Loss: 0.012696
    epoch          : 24
    loss           : 0.02183552297485232
    accuracy       : 0.9879807692307693
    f1             : 0.9839640855789185
    val_loss       : 0.05211637606627719
    val_accuracy   : 0.9711119186046512
    val_f1         : 0.960544228553772
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch24.pth ...
Train Epoch: 25 [0/21600 (0%)] Loss: 0.014074
Train Epoch: 25 [1408/21600 (7%)] Loss: 0.009825
Train Epoch: 25 [2816/21600 (13%)] Loss: 0.018810
Train Epoch: 25 [4224/21600 (20%)] Loss: 0.049309
Train Epoch: 25 [5632/21600 (26%)] Loss: 0.031971
Train Epoch: 25 [7040/21600 (33%)] Loss: 0.011135
Train Epoch: 25 [8448/21600 (39%)] Loss: 0.023587
Train Epoch: 25 [9856/21600 (46%)] Loss: 0.052220
Train Epoch: 25 [11264/21600 (52%)] Loss: 0.022137
Train Epoch: 25 [12672/21600 (59%)] Loss: 0.020932
Train Epoch: 25 [14080/21600 (65%)] Loss: 0.048201
Train Epoch: 25 [15488/21600 (72%)] Loss: 0.054203
Train Epoch: 25 [16896/21600 (78%)] Loss: 0.013118
Train Epoch: 25 [18304/21600 (85%)] Loss: 0.015261
Train Epoch: 25 [19712/21600 (91%)] Loss: 0.015909
Train Epoch: 25 [21120/21600 (98%)] Loss: 0.004282
    epoch          : 25
    loss           : 0.020670949616097466
    accuracy       : 0.9882581360946746
    f1             : 0.9843264222145081
    val_loss       : 0.052173238031046336
    val_accuracy   : 0.9739583333333334
    val_f1         : 0.9643540382385254
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch25.pth ...
Train Epoch: 26 [0/21600 (0%)] Loss: 0.019453
Train Epoch: 26 [1408/21600 (7%)] Loss: 0.024138
Train Epoch: 26 [2816/21600 (13%)] Loss: 0.020553
Train Epoch: 26 [4224/21600 (20%)] Loss: 0.011984
Train Epoch: 26 [5632/21600 (26%)] Loss: 0.023310
Train Epoch: 26 [7040/21600 (33%)] Loss: 0.005004
Train Epoch: 26 [8448/21600 (39%)] Loss: 0.023073
Train Epoch: 26 [9856/21600 (46%)] Loss: 0.017983
Train Epoch: 26 [11264/21600 (52%)] Loss: 0.021794
Train Epoch: 26 [12672/21600 (59%)] Loss: 0.013739
Train Epoch: 26 [14080/21600 (65%)] Loss: 0.047398
Train Epoch: 26 [15488/21600 (72%)] Loss: 0.019596
Train Epoch: 26 [16896/21600 (78%)] Loss: 0.023552
Train Epoch: 26 [18304/21600 (85%)] Loss: 0.008059
Train Epoch: 26 [19712/21600 (91%)] Loss: 0.013545
Train Epoch: 26 [21120/21600 (98%)] Loss: 0.017770
    epoch          : 26
    loss           : 0.02336833673424622
    accuracy       : 0.9871948964497042
    f1             : 0.982660174369812
    val_loss       : 0.050614877338629474
    val_accuracy   : 0.971656976744186
    val_f1         : 0.960821807384491
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch26.pth ...
Train Epoch: 27 [0/21600 (0%)] Loss: 0.001581
Train Epoch: 27 [1408/21600 (7%)] Loss: 0.012796
Train Epoch: 27 [2816/21600 (13%)] Loss: 0.012057
Train Epoch: 27 [4224/21600 (20%)] Loss: 0.003215
Train Epoch: 27 [5632/21600 (26%)] Loss: 0.005748
Train Epoch: 27 [7040/21600 (33%)] Loss: 0.004247
Train Epoch: 27 [8448/21600 (39%)] Loss: 0.012339
Train Epoch: 27 [9856/21600 (46%)] Loss: 0.010226
Train Epoch: 27 [11264/21600 (52%)] Loss: 0.081320
Train Epoch: 27 [12672/21600 (59%)] Loss: 0.016610
Train Epoch: 27 [14080/21600 (65%)] Loss: 0.016309
Train Epoch: 27 [15488/21600 (72%)] Loss: 0.022687
Train Epoch: 27 [16896/21600 (78%)] Loss: 0.022387
Train Epoch: 27 [18304/21600 (85%)] Loss: 0.014783
Train Epoch: 27 [19712/21600 (91%)] Loss: 0.006029
Train Epoch: 27 [21120/21600 (98%)] Loss: 0.014324
    epoch          : 27
    loss           : 0.020351832564479325
    accuracy       : 0.9890285996055227
    f1             : 0.9853246808052063
    val_loss       : 0.04371401324305077
    val_accuracy   : 0.9781976744186046
    val_f1         : 0.9694192409515381
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch27.pth ...
Saving current best: model_best.pth ...
Train Epoch: 28 [0/21600 (0%)] Loss: 0.004080
Train Epoch: 28 [1408/21600 (7%)] Loss: 0.011876
Train Epoch: 28 [2816/21600 (13%)] Loss: 0.015918
Train Epoch: 28 [4224/21600 (20%)] Loss: 0.004465
Train Epoch: 28 [5632/21600 (26%)] Loss: 0.011027
Train Epoch: 28 [7040/21600 (33%)] Loss: 0.013565
Train Epoch: 28 [8448/21600 (39%)] Loss: 0.004109
Train Epoch: 28 [9856/21600 (46%)] Loss: 0.011749
Train Epoch: 28 [11264/21600 (52%)] Loss: 0.001858
Train Epoch: 28 [12672/21600 (59%)] Loss: 0.013245
Train Epoch: 28 [14080/21600 (65%)] Loss: 0.022543
Train Epoch: 28 [15488/21600 (72%)] Loss: 0.006334
Train Epoch: 28 [16896/21600 (78%)] Loss: 0.022647
Train Epoch: 28 [18304/21600 (85%)] Loss: 0.003607
Train Epoch: 28 [19712/21600 (91%)] Loss: 0.042487
Train Epoch: 28 [21120/21600 (98%)] Loss: 0.018125
    epoch          : 28
    loss           : 0.019273694415202023
    accuracy       : 0.9883351824457595
    f1             : 0.9840938448905945
    val_loss       : 0.04335416151416423
    val_accuracy   : 0.9761991279069767
    val_f1         : 0.9687778353691101
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch28.pth ...
Saving current best: model_best.pth ...
Train Epoch: 29 [0/21600 (0%)] Loss: 0.010166
Train Epoch: 29 [1408/21600 (7%)] Loss: 0.014676
Train Epoch: 29 [2816/21600 (13%)] Loss: 0.026409
Train Epoch: 29 [4224/21600 (20%)] Loss: 0.005751
Train Epoch: 29 [5632/21600 (26%)] Loss: 0.008609
Train Epoch: 29 [7040/21600 (33%)] Loss: 0.006312
Train Epoch: 29 [8448/21600 (39%)] Loss: 0.003585
Train Epoch: 29 [9856/21600 (46%)] Loss: 0.019444
Train Epoch: 29 [11264/21600 (52%)] Loss: 0.056940
Train Epoch: 29 [12672/21600 (59%)] Loss: 0.010312
Train Epoch: 29 [14080/21600 (65%)] Loss: 0.013258
Train Epoch: 29 [15488/21600 (72%)] Loss: 0.004648
Train Epoch: 29 [16896/21600 (78%)] Loss: 0.004389
Train Epoch: 29 [18304/21600 (85%)] Loss: 0.014862
Train Epoch: 29 [19712/21600 (91%)] Loss: 0.012508
Train Epoch: 29 [21120/21600 (98%)] Loss: 0.031621
    epoch          : 29
    loss           : 0.01965154896933894
    accuracy       : 0.9890131903353057
    f1             : 0.9855234026908875
    val_loss       : 0.045926128806503014
    val_accuracy   : 0.9748667635658915
    val_f1         : 0.9646903872489929
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch29.pth ...
Train Epoch: 30 [0/21600 (0%)] Loss: 0.010462
Train Epoch: 30 [1408/21600 (7%)] Loss: 0.005910
Train Epoch: 30 [2816/21600 (13%)] Loss: 0.020258
Train Epoch: 30 [4224/21600 (20%)] Loss: 0.006036
Train Epoch: 30 [5632/21600 (26%)] Loss: 0.043287
Train Epoch: 30 [7040/21600 (33%)] Loss: 0.023683
Train Epoch: 30 [8448/21600 (39%)] Loss: 0.032802
Train Epoch: 30 [9856/21600 (46%)] Loss: 0.011504
Train Epoch: 30 [11264/21600 (52%)] Loss: 0.014741
Train Epoch: 30 [12672/21600 (59%)] Loss: 0.005058
Train Epoch: 30 [14080/21600 (65%)] Loss: 0.043297
Train Epoch: 30 [15488/21600 (72%)] Loss: 0.039571
Train Epoch: 30 [16896/21600 (78%)] Loss: 0.036765
Train Epoch: 30 [18304/21600 (85%)] Loss: 0.022860
Train Epoch: 30 [19712/21600 (91%)] Loss: 0.015554
Train Epoch: 30 [21120/21600 (98%)] Loss: 0.046869
    epoch          : 30
    loss           : 0.01925227333779155
    accuracy       : 0.9885817307692307
    f1             : 0.9849146008491516
    val_loss       : 0.043785631764940054
    val_accuracy   : 0.974079457364341
    val_f1         : 0.9639272689819336
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch30.pth ...
Train Epoch: 31 [0/21600 (0%)] Loss: 0.022612
Train Epoch: 31 [1408/21600 (7%)] Loss: 0.031669
Train Epoch: 31 [2816/21600 (13%)] Loss: 0.030293
Train Epoch: 31 [4224/21600 (20%)] Loss: 0.013867
Train Epoch: 31 [5632/21600 (26%)] Loss: 0.023196
Train Epoch: 31 [7040/21600 (33%)] Loss: 0.017226
Train Epoch: 31 [8448/21600 (39%)] Loss: 0.007629
Train Epoch: 31 [9856/21600 (46%)] Loss: 0.015650
Train Epoch: 31 [11264/21600 (52%)] Loss: 0.017901
Train Epoch: 31 [12672/21600 (59%)] Loss: 0.035327
Train Epoch: 31 [14080/21600 (65%)] Loss: 0.018237
Train Epoch: 31 [15488/21600 (72%)] Loss: 0.003063
Train Epoch: 31 [16896/21600 (78%)] Loss: 0.001432
Train Epoch: 31 [18304/21600 (85%)] Loss: 0.007045
Train Epoch: 31 [19712/21600 (91%)] Loss: 0.022798
Train Epoch: 31 [21120/21600 (98%)] Loss: 0.005658
    epoch          : 31
    loss           : 0.020121948063351523
    accuracy       : 0.9891056459566074
    f1             : 0.9858154058456421
    val_loss       : 0.043814469421239094
    val_accuracy   : 0.9781371124031009
    val_f1         : 0.9691014885902405
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch31.pth ...
Train Epoch: 32 [0/21600 (0%)] Loss: 0.030832
Train Epoch: 32 [1408/21600 (7%)] Loss: 0.037418
Train Epoch: 32 [2816/21600 (13%)] Loss: 0.038057
Train Epoch: 32 [4224/21600 (20%)] Loss: 0.026369
Train Epoch: 32 [5632/21600 (26%)] Loss: 0.022859
Train Epoch: 32 [7040/21600 (33%)] Loss: 0.005261
Train Epoch: 32 [8448/21600 (39%)] Loss: 0.043354
Train Epoch: 32 [9856/21600 (46%)] Loss: 0.022657
Train Epoch: 32 [11264/21600 (52%)] Loss: 0.023255
Train Epoch: 32 [12672/21600 (59%)] Loss: 0.013785
Train Epoch: 32 [14080/21600 (65%)] Loss: 0.004149
Train Epoch: 32 [15488/21600 (72%)] Loss: 0.039452
Train Epoch: 32 [16896/21600 (78%)] Loss: 0.017063
Train Epoch: 32 [18304/21600 (85%)] Loss: 0.015713
Train Epoch: 32 [19712/21600 (91%)] Loss: 0.018141
Train Epoch: 32 [21120/21600 (98%)] Loss: 0.004187
    epoch          : 32
    loss           : 0.01935976675984356
    accuracy       : 0.989305966469428
    f1             : 0.9859797954559326
    val_loss       : 0.04418392003470555
    val_accuracy   : 0.977592054263566
    val_f1         : 0.9707543849945068
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch32.pth ...
Train Epoch: 33 [0/21600 (0%)] Loss: 0.025371
Train Epoch: 33 [1408/21600 (7%)] Loss: 0.013224
Train Epoch: 33 [2816/21600 (13%)] Loss: 0.005198
Train Epoch: 33 [4224/21600 (20%)] Loss: 0.048286
Train Epoch: 33 [5632/21600 (26%)] Loss: 0.029427
Train Epoch: 33 [7040/21600 (33%)] Loss: 0.005743
Train Epoch: 33 [8448/21600 (39%)] Loss: 0.020122
Train Epoch: 33 [9856/21600 (46%)] Loss: 0.040438
Train Epoch: 33 [11264/21600 (52%)] Loss: 0.005132
Train Epoch: 33 [12672/21600 (59%)] Loss: 0.013767
Train Epoch: 33 [14080/21600 (65%)] Loss: 0.004673
Train Epoch: 33 [15488/21600 (72%)] Loss: 0.012349
Train Epoch: 33 [16896/21600 (78%)] Loss: 0.104210
Train Epoch: 33 [18304/21600 (85%)] Loss: 0.006354
Train Epoch: 33 [19712/21600 (91%)] Loss: 0.039537
Train Epoch: 33 [21120/21600 (98%)] Loss: 0.012561
    epoch          : 33
    loss           : 0.020841675141644415
    accuracy       : 0.9889207347140039
    f1             : 0.9854484796524048
    val_loss       : 0.04366511173632949
    val_accuracy   : 0.9757751937984497
    val_f1         : 0.9664373397827148
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch33.pth ...
Train Epoch: 34 [0/21600 (0%)] Loss: 0.031723
Train Epoch: 34 [1408/21600 (7%)] Loss: 0.006618
Train Epoch: 34 [2816/21600 (13%)] Loss: 0.010808
Train Epoch: 34 [4224/21600 (20%)] Loss: 0.047739
Train Epoch: 34 [5632/21600 (26%)] Loss: 0.042758
Train Epoch: 34 [7040/21600 (33%)] Loss: 0.002792
Train Epoch: 34 [8448/21600 (39%)] Loss: 0.019292
Train Epoch: 34 [9856/21600 (46%)] Loss: 0.013460
Train Epoch: 34 [11264/21600 (52%)] Loss: 0.033380
Train Epoch: 34 [12672/21600 (59%)] Loss: 0.012041
Train Epoch: 34 [14080/21600 (65%)] Loss: 0.013120
Train Epoch: 34 [15488/21600 (72%)] Loss: 0.004239
Train Epoch: 34 [16896/21600 (78%)] Loss: 0.013327
Train Epoch: 34 [18304/21600 (85%)] Loss: 0.034292
Train Epoch: 34 [19712/21600 (91%)] Loss: 0.001278
Train Epoch: 34 [21120/21600 (98%)] Loss: 0.016823
    epoch          : 34
    loss           : 0.019234773179394957
    accuracy       : 0.9896141518737672
    f1             : 0.986318051815033
    val_loss       : 0.03937734365679844
    val_accuracy   : 0.9807412790697675
    val_f1         : 0.9747516512870789
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch34.pth ...
Saving current best: model_best.pth ...
Train Epoch: 35 [0/21600 (0%)] Loss: 0.007065
Train Epoch: 35 [1408/21600 (7%)] Loss: 0.002935
Train Epoch: 35 [2816/21600 (13%)] Loss: 0.007007
Train Epoch: 35 [4224/21600 (20%)] Loss: 0.005148
Train Epoch: 35 [5632/21600 (26%)] Loss: 0.006575
Train Epoch: 35 [7040/21600 (33%)] Loss: 0.010411
Train Epoch: 35 [8448/21600 (39%)] Loss: 0.008160
Train Epoch: 35 [9856/21600 (46%)] Loss: 0.006770
Train Epoch: 35 [11264/21600 (52%)] Loss: 0.041871
Train Epoch: 35 [12672/21600 (59%)] Loss: 0.019390
Train Epoch: 35 [14080/21600 (65%)] Loss: 0.011394
Train Epoch: 35 [15488/21600 (72%)] Loss: 0.028825
Train Epoch: 35 [16896/21600 (78%)] Loss: 0.012586
Train Epoch: 35 [18304/21600 (85%)] Loss: 0.008331
Train Epoch: 35 [19712/21600 (91%)] Loss: 0.015944
Train Epoch: 35 [21120/21600 (98%)] Loss: 0.036833
    epoch          : 35
    loss           : 0.018287640348760157
    accuracy       : 0.9900456114398423
    f1             : 0.9867521524429321
    val_loss       : 0.03854720043235047
    val_accuracy   : 0.9797722868217055
    val_f1         : 0.9715180397033691
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch35.pth ...
Saving current best: model_best.pth ...
Train Epoch: 36 [0/21600 (0%)] Loss: 0.003925
Train Epoch: 36 [1408/21600 (7%)] Loss: 0.029546
Train Epoch: 36 [2816/21600 (13%)] Loss: 0.005761
Train Epoch: 36 [4224/21600 (20%)] Loss: 0.006995
Train Epoch: 36 [5632/21600 (26%)] Loss: 0.015072
Train Epoch: 36 [7040/21600 (33%)] Loss: 0.022602
Train Epoch: 36 [8448/21600 (39%)] Loss: 0.027905
Train Epoch: 36 [9856/21600 (46%)] Loss: 0.008850
Train Epoch: 36 [11264/21600 (52%)] Loss: 0.004967
Train Epoch: 36 [12672/21600 (59%)] Loss: 0.001494
Train Epoch: 36 [14080/21600 (65%)] Loss: 0.031166
Train Epoch: 36 [15488/21600 (72%)] Loss: 0.013244
Train Epoch: 36 [16896/21600 (78%)] Loss: 0.017326
Train Epoch: 36 [18304/21600 (85%)] Loss: 0.008998
Train Epoch: 36 [19712/21600 (91%)] Loss: 0.037683
Train Epoch: 36 [21120/21600 (98%)] Loss: 0.010069
    epoch          : 36
    loss           : 0.017056848778742084
    accuracy       : 0.9900610207100592
    f1             : 0.9868842959403992
    val_loss       : 0.03597574791096714
    val_accuracy   : 0.9807412790697675
    val_f1         : 0.9745767116546631
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch36.pth ...
Saving current best: model_best.pth ...
Train Epoch: 37 [0/21600 (0%)] Loss: 0.029249
Train Epoch: 37 [1408/21600 (7%)] Loss: 0.004885
Train Epoch: 37 [2816/21600 (13%)] Loss: 0.017535
Train Epoch: 37 [4224/21600 (20%)] Loss: 0.014032
Train Epoch: 37 [5632/21600 (26%)] Loss: 0.035512
Train Epoch: 37 [7040/21600 (33%)] Loss: 0.006253
Train Epoch: 37 [8448/21600 (39%)] Loss: 0.045362
Train Epoch: 37 [9856/21600 (46%)] Loss: 0.049345
Train Epoch: 37 [11264/21600 (52%)] Loss: 0.033011
Train Epoch: 37 [12672/21600 (59%)] Loss: 0.011649
Train Epoch: 37 [14080/21600 (65%)] Loss: 0.002747
Train Epoch: 37 [15488/21600 (72%)] Loss: 0.051972
Train Epoch: 37 [16896/21600 (78%)] Loss: 0.030172
Train Epoch: 37 [18304/21600 (85%)] Loss: 0.017402
Train Epoch: 37 [19712/21600 (91%)] Loss: 0.018345
Train Epoch: 37 [21120/21600 (98%)] Loss: 0.024883
    epoch          : 37
    loss           : 0.01788141943559811
    accuracy       : 0.9905078895463512
    f1             : 0.9874979853630066
    val_loss       : 0.03946547947694049
    val_accuracy   : 0.9806807170542636
    val_f1         : 0.9727650880813599
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch37.pth ...
Train Epoch: 38 [0/21600 (0%)] Loss: 0.020100
Train Epoch: 38 [1408/21600 (7%)] Loss: 0.006177
Train Epoch: 38 [2816/21600 (13%)] Loss: 0.003343
Train Epoch: 38 [4224/21600 (20%)] Loss: 0.019697
Train Epoch: 38 [5632/21600 (26%)] Loss: 0.002291
Train Epoch: 38 [7040/21600 (33%)] Loss: 0.072467
Train Epoch: 38 [8448/21600 (39%)] Loss: 0.015435
Train Epoch: 38 [9856/21600 (46%)] Loss: 0.057960
Train Epoch: 38 [11264/21600 (52%)] Loss: 0.018588
Train Epoch: 38 [12672/21600 (59%)] Loss: 0.009898
Train Epoch: 38 [14080/21600 (65%)] Loss: 0.048421
Train Epoch: 38 [15488/21600 (72%)] Loss: 0.002285
Train Epoch: 38 [16896/21600 (78%)] Loss: 0.004333
Train Epoch: 38 [18304/21600 (85%)] Loss: 0.013808
Train Epoch: 38 [19712/21600 (91%)] Loss: 0.022964
Train Epoch: 38 [21120/21600 (98%)] Loss: 0.007700
    epoch          : 38
    loss           : 0.017130451912705142
    accuracy       : 0.990153476331361
    f1             : 0.9868617653846741
    val_loss       : 0.038451138201581185
    val_accuracy   : 0.9818313953488372
    val_f1         : 0.9742951393127441
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch38.pth ...
Train Epoch: 39 [0/21600 (0%)] Loss: 0.020384
Train Epoch: 39 [1408/21600 (7%)] Loss: 0.028984
Train Epoch: 39 [2816/21600 (13%)] Loss: 0.019540
Train Epoch: 39 [4224/21600 (20%)] Loss: 0.006468
Train Epoch: 39 [5632/21600 (26%)] Loss: 0.026203
Train Epoch: 39 [7040/21600 (33%)] Loss: 0.006170
Train Epoch: 39 [8448/21600 (39%)] Loss: 0.012893
Train Epoch: 39 [9856/21600 (46%)] Loss: 0.005812
Train Epoch: 39 [11264/21600 (52%)] Loss: 0.004429
Train Epoch: 39 [12672/21600 (59%)] Loss: 0.011077
Train Epoch: 39 [14080/21600 (65%)] Loss: 0.026907
Train Epoch: 39 [15488/21600 (72%)] Loss: 0.012389
Train Epoch: 39 [16896/21600 (78%)] Loss: 0.011098
Train Epoch: 39 [18304/21600 (85%)] Loss: 0.022561
Train Epoch: 39 [19712/21600 (91%)] Loss: 0.010500
Train Epoch: 39 [21120/21600 (98%)] Loss: 0.009811
    epoch          : 39
    loss           : 0.017645778005995056
    accuracy       : 0.9901688856015779
    f1             : 0.9864774942398071
    val_loss       : 0.04258974547887784
    val_accuracy   : 0.977592054263566
    val_f1         : 0.9672977328300476
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch39.pth ...
Train Epoch: 40 [0/21600 (0%)] Loss: 0.005016
Train Epoch: 40 [1408/21600 (7%)] Loss: 0.003897
Train Epoch: 40 [2816/21600 (13%)] Loss: 0.024797
Train Epoch: 40 [4224/21600 (20%)] Loss: 0.012449
Train Epoch: 40 [5632/21600 (26%)] Loss: 0.017978
Train Epoch: 40 [7040/21600 (33%)] Loss: 0.027882
Train Epoch: 40 [8448/21600 (39%)] Loss: 0.031622
Train Epoch: 40 [9856/21600 (46%)] Loss: 0.045577
Train Epoch: 40 [11264/21600 (52%)] Loss: 0.007449
Train Epoch: 40 [12672/21600 (59%)] Loss: 0.008977
Train Epoch: 40 [14080/21600 (65%)] Loss: 0.018002
Train Epoch: 40 [15488/21600 (72%)] Loss: 0.014519
Train Epoch: 40 [16896/21600 (78%)] Loss: 0.024506
Train Epoch: 40 [18304/21600 (85%)] Loss: 0.006760
Train Epoch: 40 [19712/21600 (91%)] Loss: 0.006001
Train Epoch: 40 [21120/21600 (98%)] Loss: 0.007803
    epoch          : 40
    loss           : 0.016358275644304837
    accuracy       : 0.9903692061143985
    f1             : 0.986953854560852
    val_loss       : 0.035747076406381854
    val_accuracy   : 0.9827398255813954
    val_f1         : 0.9763368964195251
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch40.pth ...
Saving current best: model_best.pth ...
Train Epoch: 41 [0/21600 (0%)] Loss: 0.006556
Train Epoch: 41 [1408/21600 (7%)] Loss: 0.015539
Train Epoch: 41 [2816/21600 (13%)] Loss: 0.005789
Train Epoch: 41 [4224/21600 (20%)] Loss: 0.009802
Train Epoch: 41 [5632/21600 (26%)] Loss: 0.017640
Train Epoch: 41 [7040/21600 (33%)] Loss: 0.006374
Train Epoch: 41 [8448/21600 (39%)] Loss: 0.016065
Train Epoch: 41 [9856/21600 (46%)] Loss: 0.013193
Train Epoch: 41 [11264/21600 (52%)] Loss: 0.029561
Train Epoch: 41 [12672/21600 (59%)] Loss: 0.002735
Train Epoch: 41 [14080/21600 (65%)] Loss: 0.007034
Train Epoch: 41 [15488/21600 (72%)] Loss: 0.002889
Train Epoch: 41 [16896/21600 (78%)] Loss: 0.009802
Train Epoch: 41 [18304/21600 (85%)] Loss: 0.004240
Train Epoch: 41 [19712/21600 (91%)] Loss: 0.013821
Train Epoch: 41 [21120/21600 (98%)] Loss: 0.002431
    epoch          : 41
    loss           : 0.01572388667164139
    accuracy       : 0.9915403106508875
    f1             : 0.9888805747032166
    val_loss       : 0.03628714794433827
    val_accuracy   : 0.9831031976744186
    val_f1         : 0.9780519008636475
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch41.pth ...
Train Epoch: 42 [0/21600 (0%)] Loss: 0.005105
Train Epoch: 42 [1408/21600 (7%)] Loss: 0.026527
Train Epoch: 42 [2816/21600 (13%)] Loss: 0.028154
Train Epoch: 42 [4224/21600 (20%)] Loss: 0.014873
Train Epoch: 42 [5632/21600 (26%)] Loss: 0.005671
Train Epoch: 42 [7040/21600 (33%)] Loss: 0.002514
Train Epoch: 42 [8448/21600 (39%)] Loss: 0.017032
Train Epoch: 42 [9856/21600 (46%)] Loss: 0.005597
Train Epoch: 42 [11264/21600 (52%)] Loss: 0.032421
Train Epoch: 42 [12672/21600 (59%)] Loss: 0.002263
Train Epoch: 42 [14080/21600 (65%)] Loss: 0.008855
Train Epoch: 42 [15488/21600 (72%)] Loss: 0.005945
Train Epoch: 42 [16896/21600 (78%)] Loss: 0.009578
Train Epoch: 42 [18304/21600 (85%)] Loss: 0.003882
Train Epoch: 42 [19712/21600 (91%)] Loss: 0.010278
Train Epoch: 42 [21120/21600 (98%)] Loss: 0.008295
    epoch          : 42
    loss           : 0.015323909256158166
    accuracy       : 0.9907698471400394
    f1             : 0.9875316619873047
    val_loss       : 0.03310018052823495
    val_accuracy   : 0.9836482558139535
    val_f1         : 0.9772987365722656
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch42.pth ...
Saving current best: model_best.pth ...
Train Epoch: 43 [0/21600 (0%)] Loss: 0.006725
Train Epoch: 43 [1408/21600 (7%)] Loss: 0.013641
Train Epoch: 43 [2816/21600 (13%)] Loss: 0.007201
Train Epoch: 43 [4224/21600 (20%)] Loss: 0.004560
Train Epoch: 43 [5632/21600 (26%)] Loss: 0.005418
Train Epoch: 43 [7040/21600 (33%)] Loss: 0.019201
Train Epoch: 43 [8448/21600 (39%)] Loss: 0.051015
Train Epoch: 43 [9856/21600 (46%)] Loss: 0.005062
Train Epoch: 43 [11264/21600 (52%)] Loss: 0.008870
Train Epoch: 43 [12672/21600 (59%)] Loss: 0.039391
Train Epoch: 43 [14080/21600 (65%)] Loss: 0.007869
Train Epoch: 43 [15488/21600 (72%)] Loss: 0.003409
Train Epoch: 43 [16896/21600 (78%)] Loss: 0.060564
Train Epoch: 43 [18304/21600 (85%)] Loss: 0.037505
Train Epoch: 43 [19712/21600 (91%)] Loss: 0.009708
Train Epoch: 43 [21120/21600 (98%)] Loss: 0.009954
    epoch          : 43
    loss           : 0.017135835899530563
    accuracy       : 0.990569526627219
    f1             : 0.9874754548072815
    val_loss       : 0.031899174507490774
    val_accuracy   : 0.9861918604651163
    val_f1         : 0.9816027879714966
Saving checkpoint: saved/models/mask_age/0831_031913/checkpoint-epoch43.pth ...
Saving current best: model_best.pth ...
Train Epoch: 44 [0/21600 (0%)] Loss: 0.031802
Train Epoch: 44 [1408/21600 (7%)] Loss: 0.004071
Train Epoch: 44 [2816/21600 (13%)] Loss: 0.053928
Traceback (most recent call last):
  File "age_train.py", line 86, in <module>
    main(config)
  File "age_train.py", line 65, in main
    trainer.train()
  File "/opt/ml/level1-15/pytorch-template/base/base_trainer.py", line 67, in train
    result = self._train_epoch(epoch)
  File "/opt/ml/level1-15/pytorch-template/trainer/trainer.py", line 75, in _train_epoch
    self.optimizer.step()
  File "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 67, in wrapper
    return wrapped(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/optim/sgd.py", line 99, in step
    d_p = d_p.add(p, alpha=weight_decay)
KeyboardInterrupt