{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import pandas as pd\n",
    "from torchvision import models\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(\"/opt/ml/image-classification-level1-15/pytorch-template/data/input/data/eval/info.csv\")\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def init_models(config):\n",
    "    models = [\n",
    "        config.eval_init_obj('arch', module_arch, 1),\n",
    "        config.eval_init_obj('arch', module_arch, 2),\n",
    "        config.eval_init_obj('arch', module_arch, 3)\n",
    "    ]\n",
    "    return models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_latest_saved_model_paths(config):\n",
    "    checkpoint_path = \"/opt/ml/image-classification-level1-15/pytorch-template/saved/models/\"\n",
    "    save_paths = [\n",
    "        checkpoint_path + config['save_directory_name']['gender'],\n",
    "        checkpoint_path + config['save_directory_name']['age'],\n",
    "        checkpoint_path + config['save_directory_name']['mask']\n",
    "    ]\n",
    "\n",
    "    latest_saved_directory = [\n",
    "        sorted(os.listdir(save_paths[0]))[-1],\n",
    "        sorted(os.listdir(save_paths[1]))[-1],\n",
    "        sorted(os.listdir(save_paths[2]))[-1]\n",
    "    ]\n",
    "\n",
    "    latest_saved_model_paths = [\n",
    "        save_paths[0] + \"/\" + latest_saved_directory[0] + \"/model_best.pth\",\n",
    "        save_paths[1] + \"/\" + latest_saved_directory[1] + \"/model_best.pth\",\n",
    "        save_paths[2] + \"/\" + latest_saved_directory[2] + \"/model_best.pth\"\n",
    "    ]\n",
    "    return latest_saved_model_paths"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_saved_model_state_dict(latest_saved_model_paths):\n",
    "    checkpoint1 = torch.load(latest_saved_model_paths[0])\n",
    "    state_dict1 = checkpoint1['state_dict']\n",
    "    checkpoint2 = torch.load(latest_saved_model_paths[1])\n",
    "    state_dict2 = checkpoint2['state_dict']\n",
    "    checkpoint3 = torch.load(latest_saved_model_paths[2])\n",
    "    state_dict3 = checkpoint3['state_dict']\n",
    "\n",
    "    return [state_dict1, state_dict2, state_dict3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def main(config):\n",
    "    data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "        config['data_loader']['args']['data_dir'],\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        validation_split=0.0,\n",
    "        training=False,\n",
    "        num_workers=2,\n",
    "        csv_path=config['data_loader']['args']['csv_path'],\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model1, model2, model3 = init_models(config)\n",
    "    latest_saved_model_paths = get_latest_saved_model_paths(config)\n",
    "    state_dict1, state_dict2, state_dict3 = get_saved_model_state_dict(\n",
    "        latest_saved_model_paths)\n",
    "\n",
    "    model1.load_state_dict(state_dict1)\n",
    "    model2.load_state_dict(state_dict2)\n",
    "    model3.load_state_dict(state_dict3)\n",
    "\n",
    "    # prepare model for testing\n",
    "    model1 = model1.to(device)\n",
    "    model2 = model2.to(device)\n",
    "    model3 = model3.to(device)\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "\n",
    "    submission = pd.read_csv(\n",
    "        config['data_loader']['args']['data_dir'] + 'eval/info.csv')\n",
    "\n",
    "    gender_pred = []\n",
    "    age_pred = []\n",
    "    mask_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, image in enumerate(tqdm(data_loader)):\n",
    "            image = image.to(device)\n",
    "\n",
    "            # 0:male, 1:female\n",
    "            output1 = model1(image)\n",
    "            # 0: age < 30, 1: 30 <= age < 60, 2: 60 <= age\n",
    "            output2 = model2(image)\n",
    "            # 0: mask, 2: incorrect, 3: normal\n",
    "            output3 = model3(image)  # 마스크 착용여부\n",
    "\n",
    "            pred1 = output1.argmax(dim=-1)\n",
    "            pred2 = output2.argmax(dim=-1)\n",
    "            pred3 = output3.argmax(dim=-1)\n",
    "\n",
    "            gender_pred.extend(pred1.cpu().numpy())\n",
    "            age_pred.extend(pred2.cpu().numpy())\n",
    "            mask_pred.extend(pred3.cpu().numpy())\n",
    "\n",
    "    CLASS_DICT = {\n",
    "        '000': 0, '001': 1, '002': 2, '010': 3, '011': 4, '012': 5,\n",
    "        '100': 6, '101': 7, '102': 8, '110': 9, '111': 10, '112': 11,\n",
    "        '200': 12, '201': 13, '202': 14, '210': 15, '211': 16, '212': 17\n",
    "    }\n",
    "\n",
    "    preds = zip(gender_pred, age_pred, mask_pred)\n",
    "    labels = [CLASS_DICT[''.join(map(str, [mask, gender, age]))]\n",
    "              for gender, age, mask in preds]\n",
    "    submission['ans'] = labels\n",
    "    # submission.to_csv('hellotest.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "if __name__ == '__main__':\n",
    "    args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "    args.add_argument('-c', '--config', default=None, type=str,\n",
    "                      help='config file path (default: None)')\n",
    "    args.add_argument('-r', '--resume', default=None, type=str,\n",
    "                      help='path to latest checkpoint (default: None)')\n",
    "    args.add_argument('-d', '--device', default=None, type=str,\n",
    "                      help='indices of GPUs to enable (default: all)')\n",
    "\n",
    "    config = ConfigParser.from_args(args)\n",
    "    main(config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [-r RESUME] [-d DEVICE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"0606c01e-d0fd-472b-9e5e-db6248199ff6\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/tmp/tmp-2236gY5Chb73LPgC.json\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}