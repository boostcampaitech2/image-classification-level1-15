Target: gender
label: 0, original: 7294, flip: 4312, rotate: 0, mix: 0, total: 11606
label: 1, original: 11606, flip: 0, rotate: 0, mix: 0, total: 11606
Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth)
Model(
  (pretrained_model): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act2): ReLU(inplace=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
      )
    )
    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (fc): Linear(in_features=1000, out_features=2, bias=True)
)
Trainable parameters: 25559034
cuda:0 1
/opt/ml/baseline/image-classification-level1-15/pytorch-template/custom_dataset/custom_dataset.py:352: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  self.image_arr = np.array(images_path)
Train Epoch: 1 [0/18570 (0%)] Loss: 0.697734
Train Epoch: 1 [512/18570 (3%)] Loss: 0.204726
Train Epoch: 1 [1024/18570 (6%)] Loss: 0.459987
Train Epoch: 1 [1536/18570 (8%)] Loss: 0.186583
Train Epoch: 1 [2048/18570 (11%)] Loss: 0.249162
Train Epoch: 1 [2560/18570 (14%)] Loss: 0.124763
Train Epoch: 1 [3072/18570 (17%)] Loss: 0.374623
Train Epoch: 1 [3584/18570 (19%)] Loss: 0.377897
Train Epoch: 1 [4096/18570 (22%)] Loss: 0.134843
Train Epoch: 1 [4608/18570 (25%)] Loss: 0.290111
Train Epoch: 1 [5120/18570 (28%)] Loss: 0.467121
Train Epoch: 1 [5632/18570 (30%)] Loss: 0.134151
Train Epoch: 1 [6144/18570 (33%)] Loss: 0.365481
Train Epoch: 1 [6656/18570 (36%)] Loss: 0.110558
Train Epoch: 1 [7168/18570 (39%)] Loss: 0.130613
Train Epoch: 1 [7680/18570 (41%)] Loss: 0.150641
Train Epoch: 1 [8192/18570 (44%)] Loss: 0.070808
Train Epoch: 1 [8704/18570 (47%)] Loss: 0.139804
Train Epoch: 1 [9216/18570 (50%)] Loss: 0.220852
Train Epoch: 1 [9728/18570 (52%)] Loss: 0.110324
Train Epoch: 1 [10240/18570 (55%)] Loss: 0.150115
Train Epoch: 1 [10752/18570 (58%)] Loss: 0.275946
Train Epoch: 1 [11264/18570 (61%)] Loss: 0.074758
Train Epoch: 1 [11776/18570 (63%)] Loss: 0.275332
Train Epoch: 1 [12288/18570 (66%)] Loss: 0.257425
Train Epoch: 1 [12800/18570 (69%)] Loss: 0.036401
Train Epoch: 1 [13312/18570 (72%)] Loss: 0.048053
Train Epoch: 1 [13824/18570 (74%)] Loss: 0.052343
Train Epoch: 1 [14336/18570 (77%)] Loss: 0.087611
Train Epoch: 1 [14848/18570 (80%)] Loss: 0.123743
Train Epoch: 1 [15360/18570 (83%)] Loss: 0.036027
Train Epoch: 1 [15872/18570 (85%)] Loss: 0.086892
Train Epoch: 1 [16384/18570 (88%)] Loss: 0.023388
Train Epoch: 1 [16896/18570 (91%)] Loss: 0.029996
Train Epoch: 1 [17408/18570 (94%)] Loss: 0.102376
Train Epoch: 1 [17920/18570 (96%)] Loss: 0.140297
Train Epoch: 1 [18432/18570 (99%)] Loss: 0.107885
    epoch          : 1
    loss           : 0.14271462277454866
    accuracy       : 0.9466602233676975
    f1             : 0.9447383284568787
    val_loss       : 0.27095337477448866
    val_accuracy   : 0.8958123489121675
    val_f1         : 0.9031128287315369
Saving checkpoint: saved/models/GenderClf_AddImage2/0829_144047/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/18570 (0%)] Loss: 0.083028
Train Epoch: 2 [512/18570 (3%)] Loss: 0.118107
Train Epoch: 2 [1024/18570 (6%)] Loss: 0.233958
Train Epoch: 2 [1536/18570 (8%)] Loss: 0.095624
Train Epoch: 2 [2048/18570 (11%)] Loss: 0.083275
Train Epoch: 2 [2560/18570 (14%)] Loss: 0.036333
Train Epoch: 2 [3072/18570 (17%)] Loss: 0.090680
Train Epoch: 2 [3584/18570 (19%)] Loss: 0.034656
Train Epoch: 2 [4096/18570 (22%)] Loss: 0.052783
Train Epoch: 2 [4608/18570 (25%)] Loss: 0.141394
Train Epoch: 2 [5120/18570 (28%)] Loss: 0.099047
Train Epoch: 2 [5632/18570 (30%)] Loss: 0.067512
Train Epoch: 2 [6144/18570 (33%)] Loss: 0.046952
Train Epoch: 2 [6656/18570 (36%)] Loss: 0.074094
Train Epoch: 2 [7168/18570 (39%)] Loss: 0.082698
Train Epoch: 2 [7680/18570 (41%)] Loss: 0.013068
Train Epoch: 2 [8192/18570 (44%)] Loss: 0.204200
Train Epoch: 2 [8704/18570 (47%)] Loss: 0.114174
Train Epoch: 2 [9216/18570 (50%)] Loss: 0.159876
Train Epoch: 2 [9728/18570 (52%)] Loss: 0.058333
Train Epoch: 2 [10240/18570 (55%)] Loss: 0.057526
Train Epoch: 2 [10752/18570 (58%)] Loss: 0.206960
Train Epoch: 2 [11264/18570 (61%)] Loss: 0.098805
Train Epoch: 2 [11776/18570 (63%)] Loss: 0.039932
Train Epoch: 2 [12288/18570 (66%)] Loss: 0.011710
Train Epoch: 2 [12800/18570 (69%)] Loss: 0.092111
Train Epoch: 2 [13312/18570 (72%)] Loss: 0.196238
Train Epoch: 2 [13824/18570 (74%)] Loss: 0.021495
Train Epoch: 2 [14336/18570 (77%)] Loss: 0.096087
Train Epoch: 2 [14848/18570 (80%)] Loss: 0.013915
Train Epoch: 2 [15360/18570 (83%)] Loss: 0.033164
Train Epoch: 2 [15872/18570 (85%)] Loss: 0.068310
Train Epoch: 2 [16384/18570 (88%)] Loss: 0.074082
Train Epoch: 2 [16896/18570 (91%)] Loss: 0.050259
Train Epoch: 2 [17408/18570 (94%)] Loss: 0.007757
Train Epoch: 2 [17920/18570 (96%)] Loss: 0.021602
Train Epoch: 2 [18432/18570 (99%)] Loss: 0.028792
    epoch          : 2
    loss           : 0.07144639861795578
    accuracy       : 0.9750859106529209
    f1             : 0.9750033617019653
    val_loss       : 0.11557157896459103
    val_accuracy   : 0.9608556607574537
    val_f1         : 0.9611184000968933
Saving checkpoint: saved/models/GenderClf_AddImage2/0829_144047/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/18570 (0%)] Loss: 0.038872
Train Epoch: 3 [512/18570 (3%)] Loss: 0.017943
Train Epoch: 3 [1024/18570 (6%)] Loss: 0.052427
Train Epoch: 3 [1536/18570 (8%)] Loss: 0.032400
Train Epoch: 3 [2048/18570 (11%)] Loss: 0.018308
Train Epoch: 3 [2560/18570 (14%)] Loss: 0.019080
Train Epoch: 3 [3072/18570 (17%)] Loss: 0.066574
Train Epoch: 3 [3584/18570 (19%)] Loss: 0.012956
Train Epoch: 3 [4096/18570 (22%)] Loss: 0.029008
Train Epoch: 3 [4608/18570 (25%)] Loss: 0.058101
Train Epoch: 3 [5120/18570 (28%)] Loss: 0.015904
Train Epoch: 3 [5632/18570 (30%)] Loss: 0.040691
Train Epoch: 3 [6144/18570 (33%)] Loss: 0.046831
Train Epoch: 3 [6656/18570 (36%)] Loss: 0.016935
Train Epoch: 3 [7168/18570 (39%)] Loss: 0.042509
Train Epoch: 3 [7680/18570 (41%)] Loss: 0.054011
Train Epoch: 3 [8192/18570 (44%)] Loss: 0.084524
Train Epoch: 3 [8704/18570 (47%)] Loss: 0.007492
Train Epoch: 3 [9216/18570 (50%)] Loss: 0.217836
Train Epoch: 3 [9728/18570 (52%)] Loss: 0.037741
Train Epoch: 3 [10240/18570 (55%)] Loss: 0.061181
Train Epoch: 3 [10752/18570 (58%)] Loss: 0.015819
Train Epoch: 3 [11264/18570 (61%)] Loss: 0.040391
Train Epoch: 3 [11776/18570 (63%)] Loss: 0.041582
Train Epoch: 3 [12288/18570 (66%)] Loss: 0.030188
Train Epoch: 3 [12800/18570 (69%)] Loss: 0.020148
Train Epoch: 3 [13312/18570 (72%)] Loss: 0.054050
Train Epoch: 3 [13824/18570 (74%)] Loss: 0.072953
Train Epoch: 3 [14336/18570 (77%)] Loss: 0.091817
Train Epoch: 3 [14848/18570 (80%)] Loss: 0.046628
Train Epoch: 3 [15360/18570 (83%)] Loss: 0.080484
Train Epoch: 3 [15872/18570 (85%)] Loss: 0.131180
Train Epoch: 3 [16384/18570 (88%)] Loss: 0.012513
Train Epoch: 3 [16896/18570 (91%)] Loss: 0.014020
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/summary/writer/event_file_writer.py", line 238, in run
    self._record_writer.write(data)
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/summary/writer/record_writer.py", line 40, in write
    self._writer.write(header + header_crc + data + footer_crc)
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 531, in write
    self.fs.append(self.filename, file_content, self.binary_mode)
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 154, in append
    self._write(filename, file_content, "ab" if binary_mode else "a")
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 160, in _write
    f.write(compatify(file_content))
OSError: [Errno 28] No space left on device
Traceback (most recent call last):
  File "train.py", line 79, in <module>
    main(config)
  File "train.py", line 58, in main
    trainer.train()
  File "/opt/ml/baseline/image-classification-level1-15/pytorch-template/base/base_trainer.py", line 63, in train
    result = self._train_epoch(epoch)
  File "/opt/ml/baseline/image-classification-level1-15/pytorch-template/trainer/trainer.py", line 81, in _train_epoch
    self.train_metrics.update(
  File "/opt/ml/baseline/image-classification-level1-15/pytorch-template/utils/util.py", line 64, in update
    self.writer.add_scalar(key, value)
  File "/opt/ml/baseline/image-classification-level1-15/pytorch-template/logger/visualization.py", line 65, in wrapper
    add_data(tag, data, self.step, *args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py", line 345, in add_scalar
    self._get_file_writer().add_summary(
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py", line 97, in add_summary
    self.add_event(event, global_step, walltime)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py", line 82, in add_event
    self.event_writer.add_event(event)
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/summary/writer/event_file_writer.py", line 118, in add_event
    self._async_writer.write(event.SerializeToString())
  File "/opt/conda/lib/python3.8/site-packages/tensorboard/summary/writer/event_file_writer.py", line 171, in write
    self._byte_queue.put(bytestring)
  File "/opt/conda/lib/python3.8/queue.py", line 139, in put
    self.not_full.wait()
  File "/opt/conda/lib/python3.8/threading.py", line 302, in wait
    waiter.acquire()
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 5703) is killed by signal: Terminated. 
