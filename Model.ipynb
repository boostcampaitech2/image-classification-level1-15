{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() and True \n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "now_path = os.getcwd()\n",
    "train_path = now_path + '/input/data/train/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2700/2700 [00:00<00:00, 32882.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# class label tagging\n",
    "class_dict = {\n",
    "    ('wear', 'male', 'lt30'): (0, []),\n",
    "    ('wear', 'male', 'lt60'): (1, []),\n",
    "    ('wear', 'male', 'gte60'): (2, []),\n",
    "    ('wear', 'female', 'lt30'): (3, []),\n",
    "    ('wear', 'female', 'lt60'): (4, []),\n",
    "    ('wear', 'female', 'gte60'): (5, []),\n",
    "    ('incorrect', 'male', 'lt30'): (6, []),\n",
    "    ('incorrect', 'male', 'lt60'): (7, []),\n",
    "    ('incorrect', 'male', 'gte60'): (8, []),\n",
    "    ('incorrect', 'female', 'lt30'): (9, []),\n",
    "    ('incorrect', 'female', 'lt60'): (10, []),\n",
    "    ('incorrect', 'female', 'gte60'): (11, []),\n",
    "    ('nowear', 'male', 'lt30'): (12, []),\n",
    "    ('nowear', 'male', 'lt60'): (13, []),\n",
    "    ('nowear', 'male', 'gte60'): (14, []),\n",
    "    ('nowear', 'female', 'lt30'): (15, []),\n",
    "    ('nowear', 'female', 'lt60'): (16, []),\n",
    "    ('nowear', 'female', 'gte60'): (17, []),\n",
    "}\n",
    "\n",
    "all_files = [dir for dir in os.listdir(train_path) if dir[0] != '.']\n",
    "\n",
    "for file_name in tqdm(all_files):\n",
    "    dir_path = train_path + file_name\n",
    "    all_images = [image for image in os.listdir(dir_path) if image[0] != '.']\n",
    "    info = file_name.split('_')\n",
    "\n",
    "    gender, age = info[1], int(info[3])\n",
    "    age = 'lt30' if age < 30 else 'lt60' if age < 60 else 'gte60'\n",
    "    for img_name in all_images:\n",
    "        img_info = img_name.split('.')\n",
    "\n",
    "        if img_info[0][:4] == 'mask':         # Wear\n",
    "            wear = 'wear'\n",
    "        elif img_info[0] == 'incorrect_mask': # Incorrect\n",
    "            wear = 'incorrect'\n",
    "        elif img_info[0] == 'normal':         # Not Wear\n",
    "            wear = 'nowear'\n",
    "        \n",
    "        class_dict[(wear, gender, age)][1].append(dir_path + '/' + img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18900,\n",
       " [['/opt/ml/input/data/train/images/001022_male_Asian_21/mask4.jpg', 0],\n",
       "  ['/opt/ml/input/data/train/images/001022_male_Asian_21/mask2.jpg', 0],\n",
       "  ['/opt/ml/input/data/train/images/001022_male_Asian_21/mask1.jpg', 0],\n",
       "  ['/opt/ml/input/data/train/images/001022_male_Asian_21/mask5.jpg', 0],\n",
       "  ['/opt/ml/input/data/train/images/001022_male_Asian_21/mask3.jpg', 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "for label, img in class_dict.values():\n",
    "    for img_path in img:\n",
    "        train_data.append([img_path, label])\n",
    "len(train_data), train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, train=True):\n",
    "        self.X = [torch.tensor(np.array(Image.open(x))) for x, _ in data]\n",
    "        self.Y = [torch.tensor(y, dtype=torch.long) for _, y in data]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "class_num = 18\n",
    "epochs = 3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 512])\n",
      "torch.Size([18, 512])\n"
     ]
    }
   ],
   "source": [
    "imagenet_resnet18 = torchvision.models.resnet18(pretrained=True).to(device)\n",
    "print(imagenet_resnet18.fc.weight.shape)\n",
    "imagenet_resnet18.fc = torch.nn.Linear(in_features=512, out_features=class_num, bias=True).to(device)\n",
    "print(imagenet_resnet18.fc.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(imagenet_resnet18.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1\n",
      "Train batch 1 loss 3.119 train 0.078\n",
      "Train batch 51 loss 0.646 train 0.762\n",
      "Train batch 101 loss 0.449 train 0.811\n",
      "Train batch 151 loss 0.189 train 0.830\n",
      "Train batch 201 loss 0.287 train 0.846\n",
      "Train batch 251 loss 0.352 train 0.855\n",
      "EPOCH :  2\n",
      "Train batch 1 loss 0.259 train 0.922\n",
      "Train batch 51 loss 0.165 train 0.919\n",
      "Train batch 101 loss 0.139 train 0.925\n",
      "Train batch 151 loss 0.246 train 0.928\n",
      "Train batch 201 loss 0.145 train 0.931\n",
      "Train batch 251 loss 0.095 train 0.933\n",
      "EPOCH :  3\n",
      "Train batch 1 loss 0.147 train 0.953\n",
      "Train batch 51 loss 0.123 train 0.940\n",
      "Train batch 101 loss 0.089 train 0.949\n",
      "Train batch 151 loss 0.084 train 0.955\n",
      "Train batch 201 loss 0.096 train 0.959\n",
      "Train batch 251 loss 0.075 train 0.961\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for e in range(epochs):\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    print('EPOCH : ', e+1)\n",
    "    for batch_id, (x, y) in enumerate(dataloader):\n",
    "        \n",
    "        imagenet_resnet18.train()\n",
    "        \n",
    "        # Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "        x = x.type(torch.cuda.FloatTensor).to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Given groups=1, weight of size [64, 3, 7, 7], expected input[10, 512, 384, 3] to have 3 channels, but got 512 channels instead\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = imagenet_resnet18(x)\n",
    "        max_val, preds = torch.max(logits, 1)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (preds == y).sum().data.cpu().numpy() / preds.size()[0]\n",
    "        \n",
    "        train_acc += acc\n",
    "        \n",
    "        if batch_id % 50 == 0:\n",
    "            print('Train batch {} loss {:.3f} train {:.3f}'.format(batch_id + 1, loss.data.cpu().numpy(), train_acc / (batch_id + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "now_path = os.getcwd()\n",
    "test_path = now_path + '/input/data/eval/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[test_path + img_name, -1] for img_name in os.listdir(test_path) if img_name[0] != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "197it [00:30,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred = []\n",
    "\n",
    "imagenet_resnet18.eval()\n",
    "\n",
    "for batch_id, (x, y) in tqdm(enumerate(test_dataloader)):\n",
    "    \n",
    "    x = x.type(torch.cuda.FloatTensor).to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    \n",
    "    logits = imagenet_resnet18(x)\n",
    "    max_val, preds = torch.max(logits, 1)\n",
    "    \n",
    "    test_pred.extend(preds.cpu().tolist())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12600, 12600)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data), len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(now_path + '/input/data/eval/info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    7\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    6\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    5\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    1\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.ans = test_pred\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv(now_path + '/submit/submit01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>d71d4570505d6af8f777690e63edfa8d85ea4476.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>6cf1300e8e218716728d5820c0bab553306c2cfd.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>8140edbba31c3a824e817e6d5fb95343199e2387.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>030d439efe6fb5a7bafda45a393fc19f2bf57f54.jpg</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>f1e0b9594ae9f72571f0a9dc67406ad41f2edab0.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ImageID  ans\n",
       "0      cbc5c6e168e63498590db46022617123f1fe1268.jpg    7\n",
       "1      0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    6\n",
       "2      b549040c49190cedc41327748aeb197c1670f14d.jpg    5\n",
       "3      4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    1\n",
       "4      248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0\n",
       "...                                             ...  ...\n",
       "12595  d71d4570505d6af8f777690e63edfa8d85ea4476.jpg    2\n",
       "12596  6cf1300e8e218716728d5820c0bab553306c2cfd.jpg    0\n",
       "12597  8140edbba31c3a824e817e6d5fb95343199e2387.jpg    6\n",
       "12598  030d439efe6fb5a7bafda45a393fc19f2bf57f54.jpg   15\n",
       "12599  f1e0b9594ae9f72571f0a9dc67406ad41f2edab0.jpg   12\n",
       "\n",
       "[12600 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(now_path + '/submit/submit01.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
