{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e55b19a-e941-4efd-8205-4195d93b216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6b9f11-30ef-45ec-b422-7fdccc0dd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "    return correct / len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6903ae39-f013-4c3b-96a2-e0b589f1fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85803db8-1a9a-41eb-81c6-9d7a5436c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('images_path.pickle','rb') as f:\n",
    "    images_path = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de32ac4-21fa-4e4f-b910-bba75b5f632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "MODEL_PATH =\"saved\"\n",
    "folder_path = '/opt/ml/input/data/train/images/'\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "val_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4333ffa4-30bb-40be-a0aa-0bf6c30c7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeClassifier(nn.Module):\n",
    "    def __init__(self, num_of_classes = 3):\n",
    "        super().__init__()\n",
    "        self.m = timm.create_model('efficientnet_b1',pretrained=True)\n",
    "        self.fc = nn.Linear(self.m.classifier.out_features, num_of_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.m(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "363c4d51-77d8-4f6f-aa9e-c32701cf951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskAgeDataSet(Dataset):\n",
    "    def __init__(self,f_path,images_path,transform=None,train=True):\n",
    "        self.f_path = f_path\n",
    "        self.images_path = images_path\n",
    "        self.transform = transform\n",
    "        self.info = pd.read_csv('image_info.csv')\n",
    "        self.y = self.info['age']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        x = Image.open(self.f_path + self.images_path[index])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a0c55e-fa8b-4753-8923-abd7ad4e20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_clf = AgeClassifier()\n",
    "\n",
    "# for parm in age_clf.parameters():\n",
    "#     parm.requires_grad = False\n",
    "# for parm in age_clf.fc.parameters():\n",
    "#     parm.requires_grad = True\n",
    "mask_age_data = MaskAgeDataSet(f_path=folder_path,\n",
    "                                        images_path=images_path,\n",
    "                                        transform=transforms.Compose([transforms.RandomCrop(300),\n",
    "                                                                      transforms.RandomPerspective(),\n",
    "                                                                      transforms.RandomPerspective(),\n",
    "                                                                      transforms.RandomHorizontalFlip(),\n",
    "                                                                      transforms.RandomGrayscale(),\n",
    "                                                                      Resize((260,260)),\n",
    "                                                                      ToTensor(),\n",
    "                                                                      Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "                                                                      ]))\n",
    "\n",
    "mask_age_data_loader = DataLoader(dataset=mask_age_data,batch_size=batch_size,\n",
    "                                        shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9748a0-47fc-4c98-a1d1-9a6918e5e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_age_data, validation_data = torch.utils.data.random_split(mask_age_data,[int(len(mask_age_data)*(1-val_rate)),\n",
    "                                                                                    int(len(mask_age_data)*val_rate)])\n",
    "mask_age_data_loader = DataLoader(dataset=mask_age_data,batch_size=batch_size,\n",
    "                                        shuffle=True,drop_last=True,num_workers=4)\n",
    "validation_loader = DataLoader(dataset = validation_data, batch_size = batch_size,drop_last=True,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa992f9-b8ad-477e-b82a-770e6c95e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe34d0ad-77d8-499c-ba9b-bb94f9e41b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.45475 | Acc: 0.827 | VAcc: 0.839\n",
      "Epoch 002: | Loss: 0.29696 | Acc: 0.884 | VAcc: 0.904\n",
      "Epoch 003: | Loss: 0.25403 | Acc: 0.900 | VAcc: 0.893\n",
      "Epoch 004: | Loss: 0.22602 | Acc: 0.910 | VAcc: 0.931\n",
      "Epoch 005: | Loss: 0.20469 | Acc: 0.923 | VAcc: 0.906\n",
      "Epoch 006: | Loss: 0.16847 | Acc: 0.936 | VAcc: 0.946\n",
      "Epoch 007: | Loss: 0.17149 | Acc: 0.934 | VAcc: 0.940\n",
      "Epoch 008: | Loss: 0.13490 | Acc: 0.952 | VAcc: 0.849\n",
      "Epoch 009: | Loss: 0.13970 | Acc: 0.950 | VAcc: 0.937\n",
      "Epoch 010: | Loss: 0.12453 | Acc: 0.955 | VAcc: 0.958\n",
      "Epoch 011: | Loss: 0.11067 | Acc: 0.961 | VAcc: 0.943\n",
      "Epoch 012: | Loss: 0.11655 | Acc: 0.957 | VAcc: 0.950\n",
      "Epoch 013: | Loss: 0.10195 | Acc: 0.964 | VAcc: 0.935\n",
      "Epoch 014: | Loss: 0.11191 | Acc: 0.958 | VAcc: 0.968\n",
      "Epoch 015: | Loss: 0.09013 | Acc: 0.968 | VAcc: 0.937\n",
      "Epoch 016: | Loss: 0.10404 | Acc: 0.964 | VAcc: 0.949\n",
      "Epoch 017: | Loss: 0.08509 | Acc: 0.968 | VAcc: 0.971\n",
      "Epoch 018: | Loss: 0.08506 | Acc: 0.970 | VAcc: 0.977\n",
      "Epoch 019: | Loss: 0.07902 | Acc: 0.973 | VAcc: 0.955\n",
      "Epoch 020: | Loss: 0.07855 | Acc: 0.972 | VAcc: 0.969\n"
     ]
    }
   ],
   "source": [
    "age_clf = age_clf.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = torch.tensor([1.,1.,6.]).to(device)) # 수정필요\n",
    "optimizer = optim.Adam(age_clf.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in mask_age_data_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        y_pred = age_clf(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = accuracy(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() \n",
    "        epoch_acc += acc\n",
    "    \n",
    "    age_clf.eval()\n",
    "    vaild_acc = 0\n",
    "    for data, labels, in validation_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        y_pred = age_clf(data)\n",
    "        vacc = accuracy(y_pred, labels)\n",
    "        vaild_acc += vacc\n",
    "    age_clf.train()\n",
    "    va = f'{vaild_acc/len(validation_loader):.3f}' \n",
    "    l = f'{epoch_loss/len(mask_age_data_loader):.5f}'\n",
    "    a = f'{epoch_acc/len(mask_age_data_loader):.3f}'\n",
    "    print(f'Epoch {e+0:03}: | Loss: {l} | Acc: {a} | VAcc: {va}')\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    torch.save(age_clf.state_dict(), os.path.join(MODEL_PATH, f'age_model_{e+0:03}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea455da2-8247-43f8-bd8f-99bef541f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = nn.CrossEntropyLoss(weight=torch.tensor([1.,2.,2]))\n",
    "# b = torch.tensor([[1.,0.,0.]],requires_grad=True)\n",
    "# c = torch.LongTensor([0])\n",
    "# d = torch.LongTensor([1])\n",
    "# e = torch.LongTensor([2])\n",
    "# print(a(b,c))\n",
    "# print(a(b,d))\n",
    "# print(a(b,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0325fac-617c-48cf-b76a-e8f50bf555e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i, left in enumerate(dataloader):\n",
    "    print(i)\n",
    "    with torch.no_grad():\n",
    "        temp = model(left).view(-1, 1, 300, 300)\n",
    "    right.append(temp.to('cpu'))\n",
    "    del temp\n",
    "    torch.cuda.empty_cache()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
